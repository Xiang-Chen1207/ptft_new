# 代码全面检查报告

我已对您的预训练相关代码进行了深度审查，重点分析了 `core/engine.py`, `models/backbone.py`, `models/wrapper.py`, `core/loss.py` 以及数据处理部分。

以下是详细的检查报告：

### 1. 严重隐患 (Critical Issues) - 需立即修复

*   **NaN 梯度传播风险 (训练稳定性)**
    *   **位置**: `core/engine.py` L105-L110
    *   **问题**: 代码检测到 Loss 为 NaN/Inf 时仅打印警告，随后继续执行 `loss.backward()`。
    *   **后果**: 这会导致 NaN 梯度污染整个模型权重，使模型瞬间失效且无法恢复。
    *   **修复**: 检测到 NaN 时应跳过该 Batch 或终止训练。

*   **验证集内存溢出风险 (OOM)**
    *   **位置**: `core/engine.py` L310 (`preds.append(outputs.cpu())`)
    *   **问题**: 在 `evaluate` 函数中，将所有验证样本的预测结果存储在列表中。对于大型数据集（如 TUAB 全量验证），这会导致内存爆炸。
    *   **修复**: 仅存储必要的统计量（如混淆矩阵、累积 Loss/Accuracy），或分块计算指标。

*   **权重加载安全风险**
    *   **位置**: `models/wrapper.py` (通常在 `torch.load` 调用处)
    *   **问题**: 默认使用 `weights_only=False` (隐式或显式)。
    *   **修复**: 在 `torch.load` 中明确设置 `weights_only=True`，防止 Pickle 反序列化攻击（除非确实需要加载复杂对象）。

### 2. 代码质量与可维护性 (Code Quality)

*   **硬编码 (Hardcoding)**
    *   **位置**: `models/backbone.py`
    *   **问题**: `PatchEmbedding` 中包含大量硬编码数字：
        *   `101`: 对应 `patch_size=200` 的 FFT 频点数 (`200//2 + 1`)。如果修改 `patch_size`，模型将报错。
        *   `25`: 卷积层的通道数，作为隐层维度写死。
    *   **建议**: 将这些参数作为配置传入，或根据 `patch_size` 动态计算。

*   **Mask 广播依赖**
    *   **位置**: `models/backbone.py` L43
    *   **问题**: `mask_x[mask == 1] = self.mask_encoding` 依赖于隐式的广播机制，将 `(P,)` 的 encoding 赋值给 `(N_masked, P)` 的区域。虽然目前能跑通，但不够显式且容易出错。
    *   **建议**: 显式扩展维度或增加注释。

### 3. 功能正确性 (Correctness)

*   **R² 计算的统计偏差**
    *   **位置**: `core/engine.py` L219
    *   **问题**: 代码计算每个 Batch 的 R² 然后取平均。统计学上 R² 是非线性的，**不能直接平均**。
    *   **影响**: 监控指标可能存在轻微偏差，但不影响训练过程。
    *   **建议**: 维护全局的 `sum_sq_error` 和 `sum_sq_total`，在 Epoch 结束时统一计算全局 R²。

*   **FFT 维度依赖**
    *   **验证**: `datasets/tueg.py` 设置 `patch_size=200`，`backbone.py` 硬编码 `101`。目前是一致的，但缺乏灵活性。

### 4. 性能优化 (Performance)

*   **IO 瓶颈 (已修复)**: 之前发现的 HDF5 读取问题已通过切片读取优化。
*   **Pin Memory (已修复)**: 已在 DataLoader 中启用。
*   **混合精度训练 (AMP)**:
    *   **现状**: 代码中未发现 `torch.cuda.amp` 或 `bfloat16` 的使用。
    *   **建议**: 强烈建议引入 AMP (Automatic Mixed Precision)，通常能减少 30-50% 显存占用并加速训练。

---

### **修复计划 (Action Plan)**

我建议按照以下顺序执行修复：

1.  **修复 NaN 处理逻辑** (`core/engine.py`): 防止训练崩溃。
2.  **优化评估内存** (`core/engine.py`): 防止 OOM。
3.  **增加 AMP 支持** (`core/engine.py`): 提升训练速度。
4.  **消除硬编码** (`models/backbone.py`): 提升代码通用性。

**是否需要我为您执行这些修复？**
